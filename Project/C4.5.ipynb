{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "\n",
    "def preprocess(data, encode_labels=False, impute=False):\n",
    "    X = data.drop([\"Survived\", \"Name\", \"Ticket\", \"Cabin\"], 1)    \n",
    "    \n",
    "    if encode_labels: # for sklearn\n",
    "        X = X.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    print X.head(10)\n",
    "    \n",
    "    X = X.as_matrix()\n",
    "    \n",
    "    if impute:\n",
    "        X = Imputer().fit_transform(X)\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass  Sex  Age  SibSp  Parch  Fare  Embarked\n",
      "PassengerId                                                \n",
      "1                 2    1   28      1      0    18         3\n",
      "2                 0    0   51      1      0   207         1\n",
      "3                 2    0   34      0      0    41         3\n",
      "4                 0    0   47      1      0   189         3\n",
      "5                 2    1   47      0      0    43         3\n",
      "6                 2    1  110      0      0    51         2\n",
      "7                 0    1   69      0      0   186         3\n",
      "8                 2    1    6      3      1   124         3\n",
      "9                 2    0   35      0      2    74         3\n",
      "10                1    0   18      1      0   154         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/numpy/lib/arraysetops.py:216: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "data = DataFrame.from_csv(\"./titanic/train.csv\")\n",
    "y = data[\"Survived\"].as_matrix()\n",
    "X = preprocess(data, encode_labels=True, impute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop([\"Survived\", \"Name\", \"Ticket\", \"Cabin\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xi = X[\"Age\"].copy().as_matrix()\n",
    "yi = data[\"Survived\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yi = yi[~np.isnan(xi)]\n",
    "xi = xi[~np.isnan(xi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(xs):\n",
    "    return float(sum(xs)) / len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "datai = sorted(zip(xi, yi), key=itemgetter(0, 1))\n",
    "\n",
    "splits = []\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "last_x = None\n",
    "\n",
    "for xj, yj in datai:\n",
    "    if xj == last_x:\n",
    "        xs[-1].append(xj)\n",
    "        ys[-1].add(yj)\n",
    "    else:\n",
    "        xs.append([xj])\n",
    "        ys.append({yj})\n",
    "        \n",
    "    last_x = xj\n",
    "    \n",
    "last_label = None\n",
    "\n",
    "for xj, yj in zip(xs, ys):\n",
    "    if len(yj) == 1 and list(yj)[0] == last_label:\n",
    "        splits[-1] += xj\n",
    "    else:\n",
    "        splits.append(xj)\n",
    "        \n",
    "    if len(yj) == 1:\n",
    "        last_label = list(yj)[0]\n",
    "    else:\n",
    "        last_label = None\n",
    "        \n",
    "splits = [mean(vals) for vals in splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from math import log as logarithm\n",
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "def isnan(val):\n",
    "     return type(val) == float and math.isnan(val)\n",
    "\n",
    "isnan = np.vectorize(isnan)\n",
    "    \n",
    "class C45:\n",
    "    def __init__(self, max_depth=float(\"inf\"), min_gain=0, continuous={}, depth=0):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            max_depth: After eaching this depth, the current node is turned into a leaf which predicts\n",
    "                the most common label. This limits the capacity of the classifier and helps combat overfitting\n",
    "            min_gain: The minimum gain a split has to yield. Again, this helps overfitting\n",
    "            depth: Let's the current node know how deep it is into the tree, users usually don't need to set this\n",
    "        \"\"\"\n",
    "        \n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.continuous = continuous\n",
    "        \n",
    "        # ID3 nodes are either nodes that make a decision or leafs which constantly predict the same result\n",
    "        # We represent both possibilities using `ID3` objects and set `self.leaf` respectively\n",
    "        self.leaf = False\n",
    "        self.value = None\n",
    "        \n",
    "        self.children = {}\n",
    "        self.feature = 0\n",
    "        self.feature_split = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Creates a tree structure based on the passed data\n",
    "        \n",
    "        Arguments:\n",
    "            X: numpy array that contains the features in its rows\n",
    "            y: numpy array that contains the respective labels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.counts = Counter(y)\n",
    "        self.most_common_label = self.counts.most_common()[0][0]\n",
    "        \n",
    "        # If there is only one class left, turn this node into a leaf\n",
    "        # and always return this one value\n",
    "        if len(set(y)) == 1:\n",
    "            self.leaf = True\n",
    "            self.value = y[0]\n",
    "        # If the tree is getting to deep, turn this node into a leaf\n",
    "        # and always predict the most common value\n",
    "        elif self.depth >= self.max_depth:\n",
    "            self.leaf = True\n",
    "            self.value = self.most_common_label\n",
    "        elif len({tuple(row) for row in X}) == 1:\n",
    "            self.leaf = True\n",
    "            self.value = self.most_common_label\n",
    "        # Otherwise, look for the most informative feature and do a split on its possible values\n",
    "        else:\n",
    "            self.feature, self.feature_split = self._choose_feature(X, y)\n",
    "            \n",
    "            # If no feature is informative enough, turn this node into a leaf\n",
    "            # and always predict the most common value\n",
    "            if self.feature is None:\n",
    "                self.leaf = True\n",
    "                self.value = self.most_common_label\n",
    "            else:\n",
    "                if self.feature in self.continuous:\n",
    "                    partition = self._partition_continuous(X, y, self.feature, self.feature_split)\n",
    "                else:\n",
    "                    partition = self._partition(X, y, self.feature)\n",
    "                    \n",
    "                if self._is_useful_partition(partition):\n",
    "                    self._save_partition_proportions(partition)\n",
    "                    \n",
    "                    for value, (Xi, yi) in partition.iteritems():\n",
    "                        child = C45(continuous=self.continuous, depth=self.depth+1)\n",
    "                        child.fit(Xi, yi)\n",
    "                        self.children[value] = child\n",
    "                else:\n",
    "                    self.leaf = True\n",
    "                    self.value = self.most_common_label\n",
    "    \n",
    "    def predict_single(self, x):\n",
    "        \"\"\"\n",
    "        Predict the class of a single data point x by either using the value encoded in a leaf\n",
    "        or by following the tree structure recursively until a leaf is reached\n",
    "        \n",
    "        Arguments:\n",
    "            x: individual data point\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.leaf:\n",
    "            return self.value\n",
    "        else:\n",
    "            value = x[self.feature]\n",
    "            \n",
    "            if isnan(value):\n",
    "                return self._get_random_child_node().predict_single(x)\n",
    "            elif self.feature in self.continuous:\n",
    "                return self._predict_single_continuous(x, value)\n",
    "            else:\n",
    "                return self._predict_single_discrete(x, value)\n",
    "                \n",
    "    def _predict_single_discrete(self, x, value):\n",
    "        if value in self.children:\n",
    "            return self.children[value].predict_single(x)\n",
    "        else:\n",
    "            return self.most_common_label\n",
    "        \n",
    "    def _predict_single_continuous(self, x, value):\n",
    "        if value <= self.feature_split:\n",
    "            node = \"smaller\"\n",
    "        else:\n",
    "            node = \"greater\"\n",
    "\n",
    "        return self.children[node].predict_single(x)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the results for an entire dataset\n",
    "        \n",
    "        Arguments:\n",
    "            X: numpy array that contains each data point in a row\n",
    "        \"\"\"\n",
    "        \n",
    "        return [self.predict_single(x) for x in X]\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Returns the accuracy for predicting the given dataset X\n",
    "        \"\"\"\n",
    "        \n",
    "        correct = sum(self.predict(X) == y)\n",
    "        return float(correct) / len(y)\n",
    "        \n",
    "    def _choose_feature(self, X, y):\n",
    "        \"\"\"\n",
    "        Finds the most informative feature to split on and returns its index.\n",
    "        If no feature is informative enough, `None` is returned\n",
    "        \"\"\"\n",
    "        \n",
    "        best_feature = 0\n",
    "        best_feature_gain = -float(\"inf\")\n",
    "        best_feature_split = None\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            gain, split = self._information_gain(X, y, i)\n",
    "\n",
    "            if gain > best_feature_gain:\n",
    "                best_feature = i\n",
    "                best_feature_gain = gain\n",
    "                best_feature_split = split\n",
    "                        \n",
    "        if best_feature_gain < self.min_gain:\n",
    "            best_feature = None\n",
    "            \n",
    "        return best_feature, best_feature_split\n",
    "        \n",
    "    def _information_gain(self, X, y, feature):\n",
    "        if feature in self.continuous:\n",
    "            max_gain, best_split = self._information_gain_continuous(X, y, feature)\n",
    "            return max_gain, best_split\n",
    "        else:\n",
    "            return self._information_gain_discrete(X, y, feature), 0\n",
    "    \n",
    "    def _information_gain_continuous(self, X, y, feature):\n",
    "        \"\"\"\n",
    "        Calculates the information gain achieved by splitting on the given feature\n",
    "        \"\"\"\n",
    "        \n",
    "        data, splits = self._get_continuous_splits(X, y, feature)\n",
    "        \n",
    "        old_entropy = self._entropy(y)\n",
    "        \n",
    "        max_gain = -float(\"inf\")\n",
    "        best_split = None\n",
    "        \n",
    "        for split in splits:\n",
    "            smaller = [yi for (xi, yi) in data if xi <= split]\n",
    "            greater = [yi for (xi, yi) in data if xi > split]\n",
    "                        \n",
    "            ratio_smaller = float(len(smaller)) / len(data)\n",
    "            \n",
    "            new_entropy = ratio_smaller * self._entropy(smaller) + (1 - ratio_smaller) * self._entropy(greater)\n",
    "            \n",
    "            result = old_entropy - new_entropy\n",
    "            \n",
    "            if result > max_gain:\n",
    "                best_split = split\n",
    "                max_gain = result\n",
    "        \n",
    "        return max_gain, best_split\n",
    "    \n",
    "    def _information_gain_discrete(self, X, y, feature):\n",
    "        \"\"\"\n",
    "        Calculates the information gain achieved by splitting on the given feature\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self._entropy(y)\n",
    "        \n",
    "        summed = 0\n",
    "        \n",
    "        for value, (Xi, yi) in self._partition(X, y, feature).iteritems():\n",
    "            # Missing values should be ignored for computing the entropy\n",
    "            if not isnan(value):\n",
    "                summed += float(len(yi)) / len(y) * self._entropy(yi)\n",
    "        \n",
    "        result -= summed\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _entropy(self, X):\n",
    "        \"\"\"\n",
    "        Calculates the Shannon entropy on the given data X\n",
    "        \n",
    "        Arguments:\n",
    "            X: An iterable for feature values. Usually, this is now a 1D list\n",
    "        \"\"\"\n",
    "        \n",
    "        summed = 0\n",
    "        counter = Counter(X)\n",
    "\n",
    "        for value in counter:\n",
    "            count = counter[value]\n",
    "            px = count / float(len(X))\n",
    "            summed += px * logarithm(1. / px, 2)\n",
    "        \n",
    "        return summed\n",
    "    \n",
    "    def _partition(self, X, y, feature):\n",
    "        \"\"\"\n",
    "        Partitioning is a common operation needed for decision trees (or search trees).\n",
    "        Here, a partitioning is represented by a dictionary. The keys are values that the feature\n",
    "        can take. Under each key, we save a tuple (Xi, yi) that represents all data points (and their labels)\n",
    "        that have the respective value in the specified feature.\n",
    "        \"\"\"\n",
    "        \n",
    "        partition = defaultdict(lambda: ([], []))\n",
    "        \n",
    "        for Xi, yi in zip(X, y):\n",
    "            bucket = Xi[feature]\n",
    "            \n",
    "            partition[bucket][0].append(Xi)\n",
    "            partition[bucket][1].append(yi)\n",
    "        \n",
    "        partition = dict(partition)\n",
    "            \n",
    "        for feature, (Xi, yi) in partition.iteritems():\n",
    "            partition[feature] = (np.array(Xi), np.array(yi))\n",
    "            \n",
    "        return partition\n",
    "    \n",
    "    def _partition_continuous(self, X, y, feature, split):\n",
    "        xi = X[:, feature]\n",
    "        smaller = xi <= split\n",
    "        greater = xi > split\n",
    "        unknown = isnan(xi)\n",
    "        \n",
    "        ratio_smaller = sum(smaller) / float(sum(smaller) + sum(greater))\n",
    "        \n",
    "        unknown = np.where(unknown)[0]\n",
    "        np.random.shuffle(unknown)\n",
    "                \n",
    "        #num_first = int(ratio_smaller * len(unknown))\n",
    "        #smaller[unknown[:num_first]] = True\n",
    "        #greater[unknown[num_first:]] = True\n",
    "        \n",
    "        smaller[unknown[:len(unknown)/2]] = True\n",
    "        greater[unknown[len(unknown)/2:]] = True\n",
    "        \n",
    "        partition = {\n",
    "            \"smaller\": (X[smaller], y[smaller]),\n",
    "            \"greater\": (X[greater], y[greater])\n",
    "        }\n",
    "        \n",
    "        return partition\n",
    "    \n",
    "    def _get_continuous_splits(self, X, y, feature):\n",
    "        yi = y\n",
    "        xi = X[:, feature]\n",
    "        \n",
    "        datai = sorted(zip(xi, yi), key=itemgetter(0, 1))\n",
    "\n",
    "        splits = []\n",
    "\n",
    "        xs = []\n",
    "        ys = []\n",
    "        last_x = None\n",
    "\n",
    "        for xj, yj in datai:\n",
    "            # Missing values can't be used to find good thresholds\n",
    "            if isnan(xj):\n",
    "                continue\n",
    "                \n",
    "            if xj == last_x:\n",
    "                xs[-1].append(xj)\n",
    "                ys[-1].add(yj)\n",
    "            else:\n",
    "                xs.append([xj])\n",
    "                ys.append({yj})\n",
    "\n",
    "            last_x = xj\n",
    "\n",
    "        last_label = None\n",
    "\n",
    "        for xj, yj in zip(xs, ys):\n",
    "            if len(yj) == 1 and list(yj)[0] == last_label:\n",
    "                splits[-1] += xj\n",
    "            else:\n",
    "                splits.append(xj)\n",
    "\n",
    "            if len(yj) == 1:\n",
    "                last_label = list(yj)[0]\n",
    "            else:\n",
    "                last_label = None\n",
    "\n",
    "        splits = [mean(vals) for vals in splits]\n",
    "        \n",
    "        return datai, splits\n",
    "    \n",
    "    def _is_useful_partition(self, partition):\n",
    "        num_useful = 0\n",
    "        \n",
    "        for value, (Xi, yi) in partition.iteritems():\n",
    "            if len(yi) > 0:\n",
    "                num_useful += 1\n",
    "                \n",
    "        return num_useful >= 2\n",
    "    \n",
    "    def _save_partition_proportions(self, partition):\n",
    "        occurences = {}\n",
    "        \n",
    "        for child, (xj, xi) in partition.iteritems():\n",
    "            occurences[child] = len(xj)\n",
    "            \n",
    "        total = float(sum(occurences.values()))\n",
    "            \n",
    "        self.children_probs = { child: occ / total for child, occ in occurences.iteritems() }\n",
    "    \n",
    "    def _get_random_child_node(self):\n",
    "        name = np.random.choice(self.children_probs.keys(), p=self.children_probs.values())\n",
    "        return self.children[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "PassengerId                                                      \n",
      "1                 3    male  22.0      1      0   7.2500        S\n",
      "2                 1  female  38.0      1      0  71.2833        C\n",
      "3                 3  female  26.0      0      0   7.9250        S\n",
      "4                 1  female  35.0      1      0  53.1000        S\n",
      "5                 3    male  35.0      0      0   8.0500        S\n",
      "6                 3    male   NaN      0      0   8.4583        Q\n",
      "7                 1    male  54.0      0      0  51.8625        S\n",
      "8                 3    male   2.0      3      1  21.0750        S\n",
      "9                 3  female  27.0      0      2  11.1333        S\n",
      "10                2  female  14.0      1      0  30.0708        C\n"
     ]
    }
   ],
   "source": [
    "data = DataFrame.from_csv(\"./titanic/train.csv\")\n",
    "y = data[\"Survived\"].as_matrix()\n",
    "X = preprocess(data)#, encode_labels=True)#, impute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X[:, 2] <= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(~(X[:, 2] > 20))# & isnan(X[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = C45(continuous={2, 5})\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.94242\n",
      "test accuracy = 0.78771\n"
     ]
    }
   ],
   "source": [
    "print \"train accuracy = %.5f\" % clf.score(X_train, y_train)\n",
    "print \"test accuracy = %.5f\" % clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "child = clf\n",
    "print clf.feature\n",
    "\n",
    "while len(child.children) > 0:\n",
    "    child = child.children[child.children.keys()[0]]\n",
    "    print child.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a63967cdf723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0.0"
     ]
    }
   ],
   "source": [
    "clf.children[0.0].feature_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setNodeId(depth,index=0):\n",
    "    return str(int(depth)) + str(int(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_content(node, result_list):\n",
    "    i = 0\n",
    "    node_txt = ''\n",
    "    while i < len(node.counts.keys()):\n",
    "        tmp_result = ''\n",
    "        \n",
    "        number = node.counts[node.counts.keys()[i]]                        \n",
    "        tmp_result = result_list[node.counts.keys()[i]] + ': ' + str(number) + '\\n'\n",
    "        \n",
    "        node_txt += tmp_result\n",
    "                        \n",
    "        i += 1\n",
    "    return node_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Queue\n",
    "import pydot\n",
    "\n",
    "graph = pydot.Dot(graph_type='graph')\n",
    "\n",
    "def draw(node,feature_list, result_list):\n",
    "    \n",
    "    \n",
    "    cid = 0\n",
    "    \n",
    "    que = Queue.Queue()\n",
    "    \n",
    "    node.Id = setNodeId(node.depth)\n",
    "    que.put(node)\n",
    "    \n",
    "    while(que.qsize() > 0):\n",
    "        \n",
    "        node = que.get()\n",
    "        \n",
    "        feature = feature_list[node.feature]\n",
    "        \n",
    "        node_txt =  feature + '\\n' + show_content(node, result_list)\n",
    "        \n",
    "        graph.add_node(pydot.Node(node.Id, label = node_txt))\n",
    "        #print \"the node is: \",node\n",
    "        #print \"node's children are: \",node.children\n",
    "        \n",
    "        for index in node.children.keys():\n",
    "            if node.children[index].leaf == True:\n",
    "                #print \"this child is a leaf:\",node.children[index]\n",
    "                if len(node.children[index].counts.keys()) == 1:\n",
    "                    edge_txt = ''\n",
    "                    \n",
    "                    #print \"one child! \",node.children[index]\n",
    "                    node.children[index].Id = setNodeId(node.children[index].depth, cid)                \n",
    "                    \n",
    "                    value = node.children[index].counts[node.children[index].counts.keys()[0]]\n",
    "                    result = result_list[node.children[index].counts.keys()[0]]\n",
    "                    \n",
    "                    #print \"the result is: \",result\n",
    "                    \n",
    "                    graph.add_node(pydot.Node(node.children[index].Id, label = result + \"\\n\" + str(value), shape = 'box'))\n",
    "                    \n",
    "                    \n",
    "                    if node.feature not in node.continuous:\n",
    "                        edge_txt = str(index)\n",
    "                    else:\n",
    "                        if str(index) == \"smaller\":\n",
    "                            edge_txt = u'≤' + str(node.feature_split)\n",
    "                        else:\n",
    "                            edge_txt = '>' + str(node.feature_split)\n",
    "                    print edge_txt\n",
    "                    \n",
    "                    edge = pydot.Edge(node.Id, node.children[index].Id, label= edge_txt)\n",
    "                    graph.add_edge(edge)\n",
    "                    \n",
    "                    cid += 1\n",
    "                else:\n",
    "                    edge_txt = ''\n",
    "                    #print \"two or more children! \",node.children[index]\n",
    "                    node_txt = show_content(node.children[index], result_list)\n",
    "                        \n",
    "                    #print \"the node_txt should be: \",node_txt\n",
    "                    \n",
    "                    node.children[index].Id = setNodeId(node.children[index].depth, cid)\n",
    "                    graph.add_node(pydot.Node(node.children[index].Id, label = node_txt, shape = 'box'))\n",
    "                    \n",
    "                    if node.feature not in node.continuous:\n",
    "                        edge_txt = str(index)\n",
    "                    else:\n",
    "                        if str(index) == \"smaller\":\n",
    "                            edge_txt = u'≤' + str(node.feature_split)\n",
    "                        else:\n",
    "                            edge_txt = '>' + str(node.feature_split)\n",
    "                        \n",
    "                    print edge_txt\n",
    "                    \n",
    "                    edge = pydot.Edge(node.Id, node.children[index].Id, label= edge_txt)\n",
    "                    graph.add_edge(edge)\n",
    "                    \n",
    "                    cid += 1\n",
    "                    \n",
    "                \n",
    "            else:\n",
    "                edge_txt = ''\n",
    "                node.children[index].Id = setNodeId(node.children[index].depth, cid)                \n",
    "                \n",
    "                if node.feature not in node.continuous:\n",
    "                    edge_txt = str(index)\n",
    "                else:\n",
    "                    if str(index) == \"smaller\":\n",
    "                        edge_txt = u'≤' + str(node.feature_split)\n",
    "                    else:\n",
    "                        edge_txt = '>' + str(node.feature_split)\n",
    "                \n",
    "                print edge_txt\n",
    "                \n",
    "                edge = pydot.Edge(node.Id, node.children[index].Id, label = edge_txt)\n",
    "                graph.add_edge(edge)\n",
    "                #print \"put this node into the queue: \",node.children[index]\n",
    "                que.put(node.children[index])\n",
    "                cid += 1\n",
    "    \n",
    "    graph.write_png('./c4.5_decision_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['Pclass',  'Sex',  'Age',  'SibSp',  'Parch', 'Fare',  'Embarked']\n",
    "survive_list = ['Not Survived', 'Survived']\n",
    "\n",
    "root = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n",
      "≤26.25\n",
      ">26.25\n",
      "1\n",
      "2\n",
      "3\n",
      "≤62.0\n",
      ">62.0\n",
      "≤80.0\n",
      ">80.0\n",
      "≤2.0\n",
      ">2.0\n",
      "≤27.0\n",
      ">27.0\n",
      "≤63.0\n",
      ">63.0\n",
      "≤14.6\n",
      ">14.6\n",
      "≤71.5\n",
      ">71.5\n",
      "≤80.0\n",
      ">80.0\n",
      "0\n",
      "8\n",
      "≤2.0\n",
      ">2.0\n",
      "≤28.7125\n",
      ">28.7125\n",
      "≤21.0\n",
      ">21.0\n",
      "≤63.0\n",
      ">63.0\n",
      "Q\n",
      "C\n",
      "S\n",
      "≤11.0\n",
      ">11.0\n",
      "≤62.0\n",
      ">62.0\n",
      "≤70.25\n",
      ">70.25\n",
      "≤74.0\n",
      ">74.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "8\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "≤26.7333333333\n",
      ">26.7333333333\n",
      "0\n",
      "1\n",
      "2\n",
      "Q\n",
      "S\n",
      "C\n",
      "≤22.025\n",
      ">22.025\n",
      "0\n",
      "1\n",
      "2\n",
      "≤7.75\n",
      ">7.75\n",
      "0\n",
      "1\n",
      "2\n",
      "≤11.0\n",
      ">11.0\n",
      "≤12.0\n",
      ">12.0\n",
      "≤10.5\n",
      ">10.5\n",
      "Q\n",
      "S\n",
      "C\n",
      "≤70.5\n",
      ">70.5\n",
      "≤74.0\n",
      ">74.0\n",
      "Q\n",
      "C\n",
      "S\n",
      "≤52.0\n",
      ">52.0\n",
      "1\n",
      "2\n",
      "3\n",
      "≤1.0\n",
      ">1.0\n",
      "1\n",
      "2\n",
      "S\n",
      "C\n",
      "≤35.5\n",
      ">35.5\n",
      "≤44.0\n",
      ">44.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "≤5.0\n",
      ">5.0\n",
      "≤7.6292\n",
      ">7.6292\n",
      "≤7.7333\n",
      ">7.7333\n",
      "0\n",
      "1\n",
      "≤15.2458\n",
      ">15.2458\n",
      "≤11.0\n",
      ">11.0\n",
      "≤12.0\n",
      ">12.0\n",
      "Q\n",
      "S\n",
      "C\n",
      "≤32.0\n",
      ">32.0\n",
      "Q\n",
      "S\n",
      "C\n",
      "1\n",
      "2\n",
      "3\n",
      "Q\n",
      "S\n",
      "≤74.0\n",
      ">74.0\n",
      "≤26.55\n",
      ">26.55\n",
      "≤27.075\n",
      ">27.075\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "≤8.0\n",
      ">8.0\n",
      "1\n",
      "2\n",
      "≤3.0\n",
      ">3.0\n",
      "≤26.55\n",
      ">26.55\n",
      "≤27.7208\n",
      ">27.7208\n",
      "≤120.0\n",
      ">120.0\n",
      "≤10.5\n",
      ">10.5\n",
      "≤63.0\n",
      ">63.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "≤2.0\n",
      ">2.0\n",
      "≤7.2292\n",
      ">7.2292\n",
      "0\n",
      "1\n",
      "2\n",
      "≤12.0\n",
      ">12.0\n",
      "≤7.225\n",
      ">7.225\n",
      "≤26.0\n",
      ">26.0\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "≤8.05\n",
      ">8.05\n",
      "≤74.0\n",
      ">74.0\n",
      "≤35.0\n",
      ">35.0\n",
      "≤36.0\n",
      ">36.0\n",
      "≤35.5\n",
      ">35.5\n",
      "≤52.0\n",
      ">52.0\n",
      "≤79.2\n",
      ">79.2\n",
      "≤44.0\n",
      ">44.0\n",
      "≤35.0\n",
      ">35.0\n",
      "0\n",
      "2\n",
      "≤7.75\n",
      ">7.75\n",
      "0\n",
      "1\n",
      "≤18.0\n",
      ">18.0\n",
      "≤14.4\n",
      ">14.4\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "3\n",
      "≤12.0\n",
      ">12.0\n",
      "≤25.0\n",
      ">25.0\n",
      "≤27.0\n",
      ">27.0\n",
      "≤35.5\n",
      ">35.5\n",
      "≤44.0\n",
      ">44.0\n",
      "≤42.0\n",
      ">42.0\n",
      "≤14.4542\n",
      ">14.4542\n",
      "≤45.0\n",
      ">45.0\n",
      "≤7.33333333333\n",
      ">7.33333333333\n",
      "≤52.0\n",
      ">52.0\n",
      "≤80.0\n",
      ">80.0\n",
      "≤18.5\n",
      ">18.5\n",
      "≤71.0\n",
      ">71.0\n",
      "≤29.7\n",
      ">29.7\n",
      "≤6.75\n",
      ">6.75\n",
      "Q\n",
      "S\n",
      "C\n",
      "≤9.35\n",
      ">9.35\n",
      "≤1.0\n",
      ">1.0\n",
      "Q\n",
      "S\n",
      "C\n",
      "≤28.0625\n",
      ">28.0625\n",
      "≤36.0\n",
      ">36.0\n",
      "≤7.925\n",
      ">7.925\n",
      "≤24.0476190476\n",
      ">24.0476190476\n",
      "≤42.0\n",
      ">42.0\n",
      "1\n",
      "2\n",
      "3\n",
      "≤30.5\n",
      ">30.5\n",
      "≤55.0\n",
      ">55.0\n",
      "C\n",
      "S\n",
      "≤37.0\n",
      ">37.0\n",
      "≤7.48385\n",
      ">7.48385\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "≤4.0\n",
      ">4.0\n",
      "≤24.5\n",
      ">24.5\n",
      "≤15.0\n",
      ">15.0\n",
      "≤7.360425\n",
      ">7.360425\n",
      "Q\n",
      "C\n",
      "S\n",
      "≤27.4545454545\n",
      ">27.4545454545\n",
      "≤17.0\n",
      ">17.0\n",
      "≤28.0\n",
      ">28.0\n",
      "0\n",
      "1\n",
      "≤56.0\n",
      ">56.0\n",
      "≤25.0\n",
      ">25.0\n",
      "≤38.0\n",
      ">38.0\n",
      "≤45.0\n",
      ">45.0\n",
      "≤24.0\n",
      ">24.0\n",
      "≤10.31\n",
      ">10.31\n",
      "≤10.4625\n",
      ">10.4625\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "≤22.0\n",
      ">22.0\n",
      "Q\n",
      "S\n",
      "C\n",
      "≤41.5\n",
      ">41.5\n",
      "≤29.6\n",
      ">29.6\n",
      "≤30.8\n",
      ">30.8\n",
      "≤26.0\n",
      ">26.0\n",
      "≤45.5\n",
      ">45.5\n",
      "≤30.0\n",
      ">30.0\n",
      "≤28.0\n",
      ">28.0\n",
      "≤19.0\n",
      ">19.0\n",
      "≤7.63332\n",
      ">7.63332\n",
      "≤22.0\n",
      ">22.0\n",
      "≤25.0\n",
      ">25.0\n",
      "≤24.0\n",
      ">24.0\n",
      "≤16.0\n",
      ">16.0\n",
      "≤9.06538461538\n",
      ">9.06538461538\n",
      "≤0.0\n",
      ">0.0\n",
      "≤4.0125\n",
      ">4.0125\n",
      "≤29.0\n",
      ">29.0\n",
      "≤30.0\n",
      ">30.0\n",
      "≤35.375\n",
      ">35.375\n",
      "≤42.5\n",
      ">42.5\n",
      "≤30.3333333333\n",
      ">30.3333333333\n",
      "≤76.7292\n",
      ">76.7292\n",
      "0\n",
      "1\n",
      "≤58.0\n",
      ">58.0\n",
      "≤48.5\n",
      ">48.5\n",
      "≤27.0\n",
      ">27.0\n",
      "≤45.0\n",
      ">45.0\n",
      "≤9.8417\n",
      ">9.8417\n",
      "≤26.3333333333\n",
      ">26.3333333333\n",
      "≤28.5\n",
      ">28.5\n",
      "≤19.0\n",
      ">19.0\n",
      "≤8.65892857143\n",
      ">8.65892857143\n",
      "≤20.0\n",
      ">20.0\n",
      "≤29.0\n",
      ">29.0\n",
      "≤7.775\n",
      ">7.775\n",
      "≤36.6\n",
      ">36.6\n",
      "≤43.0\n",
      ">43.0\n",
      "≤32.0\n",
      ">32.0\n",
      "≤27.0\n",
      ">27.0\n",
      "≤30.5\n",
      ">30.5\n",
      "≤49.0\n",
      ">49.0\n",
      "≤29.0\n",
      ">29.0\n",
      "≤22.0\n",
      ">22.0\n",
      "≤14.0\n",
      ">14.0\n",
      "≤7.8958\n",
      ">7.8958\n",
      "≤36.0\n",
      ">36.0\n",
      "≤16.0\n",
      ">16.0\n",
      "≤7.225\n",
      ">7.225\n",
      "2\n",
      "3\n",
      "≤31.0\n",
      ">31.0\n",
      "≤39.0\n",
      ">39.0\n",
      "≤31.0\n",
      ">31.0\n",
      "≤13.0\n",
      ">13.0\n",
      "≤35.0\n",
      ">35.0\n",
      "≤36.0\n",
      ">36.0\n",
      "≤16.0\n",
      ">16.0\n",
      "≤18.0\n",
      ">18.0\n",
      "≤27.0\n",
      ">27.0\n",
      "≤31.0\n",
      ">31.0\n",
      "≤7.775\n",
      ">7.775\n",
      "≤22.1\n",
      ">22.1\n",
      "≤8.76665\n",
      ">8.76665\n",
      "≤7.8542\n",
      ">7.8542\n",
      "≤37.5\n",
      ">37.5\n",
      "≤33.0\n",
      ">33.0\n",
      "≤31.0\n",
      ">31.0\n",
      "≤31.0\n",
      ">31.0\n",
      "≤21.0\n",
      ">21.0\n",
      "≤7.775\n",
      ">7.775\n",
      "≤7.775\n",
      ">7.775\n",
      "≤8.6625\n",
      ">8.6625\n",
      "≤21.0\n",
      ">21.0\n",
      "≤7.1417\n",
      ">7.1417\n",
      "≤9.4833\n",
      ">9.4833\n",
      "≤7.8958\n",
      ">7.8958\n",
      "≤38.0\n",
      ">38.0\n",
      "≤39.0\n",
      ">39.0\n",
      "≤7.65\n",
      ">7.65\n",
      "≤30.5\n",
      ">30.5\n",
      "≤7.85834285714\n",
      ">7.85834285714\n",
      "≤8.05\n",
      ">8.05\n",
      "≤34.0\n",
      ">34.0\n",
      "≤37.0\n",
      ">37.0\n",
      "≤7.7958\n",
      ">7.7958\n",
      "0\n",
      "1\n",
      "≤7.925\n",
      ">7.925\n",
      "≤31.0\n",
      ">31.0\n",
      "≤18.5\n",
      ">18.5\n",
      "≤19.0\n",
      ">19.0\n",
      "≤19.25\n",
      ">19.25\n",
      "≤7.8958\n",
      ">7.8958\n",
      "≤20.0\n",
      ">20.0\n",
      "≤8.05\n",
      ">8.05\n",
      "≤7.25\n",
      ">7.25\n"
     ]
    }
   ],
   "source": [
    "draw(root, feature_list, survive_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print \"train accuracy = %.5f\" % clf.score(X_train, y_train)\n",
    "print \"test accuracy = %.5f\" % clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
